{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analysis\n",
    "In this notebook we will practice the following items:\n",
    "+ Text data vectorization\n",
    "- Additional machine learning models\n",
    "- apply supervised machine learning on text data, specifically\n",
    "- Text classification (into topics) using 20newsgroup data\n",
    "- Familiarize with the `pipeline` object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Import python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV \n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# linear regression\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "# show several prints in one cell. This will allow us to condence every trick in one cell.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Vectorization\n",
    "In the vectorization process of text features we need to convert text to a set of representative numerical values.<br/>\n",
    "For example, most automatic mining of social media data relies on some form of encoding the text as numbers.<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will review following Sickit Learn vectorizers: \n",
    "* The CountVectorizer\n",
    "* The TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### The CountVectorizer\n",
    "One of the simplest methods of encoding data is by *word counts*: <br/>\n",
    "you take each snippet of text, count the occurrences of each word within it, <br/>\n",
    "and put the results in a table.\n",
    "\n",
    "For example, consider the following set of three phrases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample = ['problem of evil',\n",
    "          'evil queen is evil',\n",
    "          'horizon problem']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For a vectorization of this data based on word count, we could construct <br/>\n",
    "   a column representing the word \"problem,\" the word \"evil,\" the word \"horizon,\" and so on.<br/>\n",
    "   \n",
    "While doing this by hand would be possible, the tedium can be avoided by using Scikit-Learn's ``CountVectorizer``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['problem of evil', 'evil queen is evil', 'horizon problem']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<3x6 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 1, 0],\n",
       "       [2, 0, 1, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evil</th>\n",
       "      <th>horizon</th>\n",
       "      <th>is</th>\n",
       "      <th>of</th>\n",
       "      <th>problem</th>\n",
       "      <th>queen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   evil  horizon  is  of  problem  queen\n",
       "0     1        0   0   1        1      0\n",
       "1     2        0   1   0        0      1\n",
       "2     0        1   0   0        1      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample\n",
    "vec = CountVectorizer()\n",
    "X_train = vec.fit_transform(sample)\n",
    "type(X_train)\n",
    "X_train\n",
    "type(X_train.toarray())\n",
    "X_train.toarray()\n",
    "pd.DataFrame(X_train.toarray(), columns=vec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Some parameters you should review:\n",
    "* **analyzer** - default=’word’ but we could change to ‘char’, ‘char_wb’\n",
    "  * Option ‘char_wb’ creates character n-grams only from text inside word boundaries\n",
    "* **tokenizer** - Override the string tokenization step while preserving the preprocessing and n-grams generation steps\n",
    "* **stop_words** - if a list is set (stop_words=python_lst), it is assumed to contain stop words, all of which will be removed from the resulting tokens.\n",
    "* **ngram_range** - tuple - (min_n, max_n), default=(1, 1) - if changed we could catch ngrams.\n",
    "* **min_df** - float in range [0.0, 1.0] or int, default=1 - the minimum number of documents (or ratio of documents), for which the word (or basic unit) should appear in.\n",
    "* **max_df** - float in range [0.0, 1.0] or int, default=1.0 - the maximum number of documents (or ratio of documents), for which the word (or basic unit) should appear in.\n",
    "* **max_features** - int, default=None - max_features ordered by term frequency across the corpus.\n",
    "\n",
    "For additional information click the link: [sklearn's CountVectorizer documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Mini Exercise 1 \n",
    "Use the `sample` list as input and do the following:\n",
    "1. Fit a `CountVectorizer` to the `sample` data.\n",
    "2. Use the `stop_words` parameter with ['is', 'of'] as stop words <br/>\n",
    "3. Use the `ngram_range` parameter for both unigram (one word) and bigrams (two words)<br/>\n",
    "4. display the vectorized dataset<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evil</th>\n",
       "      <th>evil queen</th>\n",
       "      <th>horizon</th>\n",
       "      <th>horizon problem</th>\n",
       "      <th>problem</th>\n",
       "      <th>problem evil</th>\n",
       "      <th>queen</th>\n",
       "      <th>queen evil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   evil  evil queen  horizon  horizon problem  problem  problem evil  queen  \\\n",
       "0     1           0        0                0        1             1      0   \n",
       "1     2           1        0                0        0             0      1   \n",
       "2     0           0        1                1        1             0      0   \n",
       "\n",
       "   queen evil  \n",
       "0           0  \n",
       "1           1  \n",
       "2           0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = CountVectorizer(stop_words=['is', 'of'], ngram_range=(1, 2))\n",
    "X_train = vec.fit_transform(sample)\n",
    "X_train = pd.DataFrame(X_train.toarray(), columns=vec.get_feature_names_out())\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Mini Exercise 2\n",
    "Use the `sample` list as input and do the following:\n",
    "1. Fit a `CountVectorizer` to the `sample` data.\n",
    "2. now use the `analyzer` with the `char` value<br/>\n",
    "3. Use the `ngram_range` parameter for a (3,4) range<br/>\n",
    "4. display the vectorized dataset<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ev</th>\n",
       "      <th>evi</th>\n",
       "      <th>is</th>\n",
       "      <th>is</th>\n",
       "      <th>of</th>\n",
       "      <th>of</th>\n",
       "      <th>pr</th>\n",
       "      <th>pro</th>\n",
       "      <th>qu</th>\n",
       "      <th>que</th>\n",
       "      <th>...</th>\n",
       "      <th>rob</th>\n",
       "      <th>robl</th>\n",
       "      <th>s e</th>\n",
       "      <th>s ev</th>\n",
       "      <th>uee</th>\n",
       "      <th>ueen</th>\n",
       "      <th>vil</th>\n",
       "      <th>vil</th>\n",
       "      <th>zon</th>\n",
       "      <th>zon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ev   evi   is   is    of   of    pr   pro   qu   que  ...  rob  robl  s e  \\\n",
       "0    1     1    0     0    1     1    0     0    0     0  ...    1     1    0   \n",
       "1    1     1    1     1    0     0    0     0    1     1  ...    0     0    1   \n",
       "2    0     0    0     0    0     0    1     1    0     0  ...    1     1    0   \n",
       "\n",
       "   s ev  uee  ueen  vil  vil   zon  zon   \n",
       "0     0    0     0    1     0    0     0  \n",
       "1     1    1     1    2     1    0     0  \n",
       "2     0    0     0    0     0    1     1  \n",
       "\n",
       "[3 rows x 64 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ev</th>\n",
       "      <th>evi</th>\n",
       "      <th>is</th>\n",
       "      <th>is</th>\n",
       "      <th>of</th>\n",
       "      <th>of</th>\n",
       "      <th>pr</th>\n",
       "      <th>pro</th>\n",
       "      <th>qu</th>\n",
       "      <th>que</th>\n",
       "      <th>...</th>\n",
       "      <th>rob</th>\n",
       "      <th>robl</th>\n",
       "      <th>s e</th>\n",
       "      <th>s ev</th>\n",
       "      <th>uee</th>\n",
       "      <th>ueen</th>\n",
       "      <th>vil</th>\n",
       "      <th>vil</th>\n",
       "      <th>zon</th>\n",
       "      <th>zon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ev   evi   is   is    of   of    pr   pro   qu   que  ...  rob  robl  s e  \\\n",
       "0    1     1    0     0    1     1    0     0    0     0  ...    1     1    0   \n",
       "1    1     1    1     1    0     0    0     0    1     1  ...    0     0    1   \n",
       "2    0     0    0     0    0     0    1     1    0     0  ...    1     1    0   \n",
       "\n",
       "   s ev  uee  ueen  vil  vil   zon  zon   \n",
       "0     0    0     0    1     0    0     0  \n",
       "1     1    1     1    2     1    0     0  \n",
       "2     0    0     0    0     0    1     1  \n",
       "\n",
       "[3 rows x 64 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = CountVectorizer(analyzer='char', ngram_range=(3, 4))\n",
    "X_train = vec.fit_transform(sample)\n",
    "X_train = pd.DataFrame(X_train.toarray(), columns=vec.get_feature_names_out())\n",
    "X_train\n",
    "\n",
    "vec_char_ngrams = CountVectorizer(analyzer='char', tokenizer=lambda x:x.split(), ngram_range=(3,4))\n",
    "X_train = vec_char_ngrams.fit_transform(sample)\n",
    "pd.DataFrame(X_train.toarray(), columns=vec_char_ngrams.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### The TfidfVectorizer\n",
    "There are some issues with the `CountVectorizer` approach, <br/>\n",
    "   the raw word counts lead to features which put too much weight on words that appear very frequently, <br/>\n",
    "   and this can be sub-optimal in some classification algorithms.<br/>\n",
    "\n",
    "One approach to fix this is known as *term frequency-inverse document frequency* (*TF–IDF*),<br/>\n",
    "   which weights the word counts by a measure of how often they appear in the documents.<br/>\n",
    "The syntax for computing these features is similar to the previous example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Some parameters you should review:\n",
    "* **norm** -  default=’l2’ - ‘l1’ also possible. \n",
    "  * `'l2'` - sum of squares of vector elements is 1,\n",
    "  * `'l1'` - Sum of absolute values of vector elements is 1\n",
    "* **use_idf** - bool, default=True - if is False, like CountVectorizer, but with tf, instead of count.\n",
    "* **sublinear_tf** - bool, default=False - if is True (zipf law), replace tf with 1 + log(tf).\n",
    "* **stop_words** - if a list is set (stop_words=python_lst), it is assumed to contain stop words, all of which will be removed from the resulting tokens.\n",
    "* **ngram_range** - tuple - (min_n, max_n), default=(1, 1) - if changed we could catch ngrams.\n",
    "* **min_df** - float in range [0.0, 1.0] or int, default=1 - the minimum number of documents (or ratio of documents), for which the word (or basic unit) should appear in.\n",
    "* **max_df** - float in range [0.0, 1.0] or int, default=1.0 - the maximum number of documents (or ratio of documents), for which the word (or basic unit) should appear in.\n",
    "* **max_features** - int, default=None - max_features ordered by term frequency across the corpus.\n",
    "\n",
    "For additional information click the link: [sklearn's TfidfVectorizer documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['problem of evil', 'evil queen is evil', 'horizon problem']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evil</th>\n",
       "      <th>horizon</th>\n",
       "      <th>is</th>\n",
       "      <th>of</th>\n",
       "      <th>problem</th>\n",
       "      <th>queen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.517856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.680919</td>\n",
       "      <td>0.517856</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.732359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.481482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.481482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.795961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.605349</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       evil   horizon        is        of   problem     queen\n",
       "0  0.517856  0.000000  0.000000  0.680919  0.517856  0.000000\n",
       "1  0.732359  0.000000  0.481482  0.000000  0.000000  0.481482\n",
       "2  0.000000  0.795961  0.000000  0.000000  0.605349  0.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = TfidfVectorizer()\n",
    "X_train_idf = vec.fit_transform(sample)\n",
    "sample\n",
    "pd.DataFrame(X_train_idf.toarray(), columns=vec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Mini Exercise 3\n",
    "Use the `sample` list as input and do the following:\n",
    "1. Fit a `TfidfVectorizer` to the `sample` data.\n",
    "2. now use the `sublinear_tf ` with the True value and `use_idf` as False (this is actually a CountVectorizer, as we studied in the lecture)<br/>\n",
    "3. display the vectorized dataset<br/>\n",
    "4. Now try the `min_df` parameter with a value of 2, what changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evil</th>\n",
       "      <th>horizon</th>\n",
       "      <th>is</th>\n",
       "      <th>of</th>\n",
       "      <th>problem</th>\n",
       "      <th>queen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.767495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.453295</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.453295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       evil   horizon        is       of   problem     queen\n",
       "0  0.577350  0.000000  0.000000  0.57735  0.577350  0.000000\n",
       "1  0.767495  0.000000  0.453295  0.00000  0.000000  0.453295\n",
       "2  0.000000  0.707107  0.000000  0.00000  0.707107  0.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evil</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       evil   problem\n",
       "0  0.707107  0.707107\n",
       "1  1.000000  0.000000\n",
       "2  0.000000  1.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = TfidfVectorizer(sublinear_tf=True, use_idf=False)\n",
    "X_train = vec.fit_transform(sample)\n",
    "pd.DataFrame(X_train.toarray(), columns=vec.get_feature_names_out())\n",
    "\n",
    "vec = TfidfVectorizer(sublinear_tf=True, use_idf=False, min_df=2)\n",
    "X_train = vec.fit_transform(sample)\n",
    "pd.DataFrame(X_train.toarray(), columns=vec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Additional Machine Learning models\"\n",
    "Some Other models, some of which we did not study **yet**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import the iris dataset\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# load another sample dataset for regression\n",
    "diabetes = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Linear Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear regression\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(diabetes.data, diabetes.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10)\n",
      "(10,) [ -10.01219782 -239.81908937  519.83978679  324.39042769 -792.18416163\n",
      "  476.74583782  101.04457032  177.06417623  751.27932109   67.62538639]\n",
      "152.1334841628965\n"
     ]
    }
   ],
   "source": [
    "# regression coefficients\n",
    "print(diabetes.data.shape)\n",
    "print(regr.coef_.shape,regr.coef_)\n",
    "print(regr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2859.6903987680657"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean squared error\n",
    "np.mean((regr.predict(diabetes.data)-diabetes.target)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5177494254132934"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explained variance (r^2)\n",
    "regr.score(diabetes.data, diabetes.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=3, n_init=5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2 1 2 2 2 2\n",
      " 2 2 1 1 2 2 2 2 1 2 1 2 1 2 2 1 1 2 2 2 2 2 1 2 2 2 2 1 2 2 2 1 2 2 2 1 2\n",
      " 2 1]\n",
      "[[5.006      3.428      1.462      0.246     ]\n",
      " [5.9016129  2.7483871  4.39354839 1.43387097]\n",
      " [6.85       3.07368421 5.74210526 2.07105263]]\n"
     ]
    }
   ],
   "source": [
    "# k means clustering\n",
    "k_means = KMeans(n_clusters=3, init='k-means++', n_init=5)\n",
    "k_means.fit(iris.data)\n",
    "print(k_means.labels_)\n",
    "print(k_means.cluster_centers_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, max_iter=5, random_state=42, tol=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_svm_cls = SGDClassifier(loss='hinge', penalty='l2', \n",
    "                    alpha=1e-3, random_state=42, max_iter=5, tol=None)\n",
    "sgd_svm_cls.fit(iris.data[:-2], iris.target[:-2])\n",
    "sgd_svm_cls.predict(iris.data[-2:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_svm_cls=LinearSVC()\n",
    "linear_svm_cls.fit(iris.data[:-2], iris.target[:-2])\n",
    "linear_svm_cls.predict(iris.data[-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=1e-05, max_iter=10, random_state=42)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron_cls=Perceptron(tol=1e-3, random_state=42, alpha=0.00001, max_iter=10)\n",
    "perceptron_cls.fit(iris.data[:-2], iris.target[:-2])\n",
    "perceptron_cls.predict(iris.data[-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Artificial Neural Networks (ANN):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', solver='sgd')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_cls = MLPClassifier(activation='logistic',solver='sgd')\n",
    "mlp_cls.fit(iris.data[:-2], iris.target[:-2])\n",
    "mlp_cls.predict(iris.data[-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text processing - Text Classification pipeline\n",
    "Let's get familiarize with the `pipeline` object\n",
    "\n",
    "**Text Classification Flow**\n",
    "\n",
    "For this task we will use a dataset called “Twenty Newsgroups”. This is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups (topics). The 20 newsgroups collection has become a popular data set for experiments in text applications of machine learning techniques, such as text classification and text clustering.\n",
    "\n",
    "We will use the built-in [dataset loader for 20 newsgroups](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html#loading-the-20-newsgroups-dataset) from scikit-learn. Our task is to train a classifier to correctly classify a new post into one of the topics (newsgroups) based on its content. We will use part of the examples provided [here](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html#training-a-classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=12) # use sklearn's method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look on some of the documents (feel free to change the document id's you look on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: hrs1@cbnewsi.cb.att.com (herman.r.silbiger)\n",
      "Subject: ANSI/AIIM MS-53 Standard Image File Format\n",
      "Organization: AT&T\n",
      "Keywords: image, file format\n",
      "Lines: 6\n",
      "wing the suggestion of Stu Lynne, I have posted the Image File Format executable and source code to alt.sources.\n",
      "Herman Silbiger\n",
      ".\n",
      "it's topic id is: 1\n",
      "it's topic name is: comp.graphics\n"
     ]
    }
   ],
   "source": [
    "doc_id=11\n",
    "print('\\n'.join([line for line in twenty_train.data[doc_id].split('\\n') if line.strip()])) # looking on the first doc\n",
    "print(\"it's topic id is:\",twenty_train.target[doc_id])\n",
    "print(\"it's topic name is:\",twenty_train.target_names[twenty_train.target[doc_id]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look on the 20 topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 5 classes:\n",
    "twenty_train.target_names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to turn it into a feature matrix (do you remember how to do it?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 129796)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer(stop_words=\"english\")\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Over 120,000 features! That's might be too much, we don't need all of them, let's limit ourselves to the top 10000 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 10000)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer(stop_words=\"english\",max_features=10000)\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's more reasonable (you can always test later again, what happens if you keep the larger number of features, or reduce the number even more aggressively)\n",
    "\n",
    "As seen earlier, it's recommended now to normalize the data (according to the relative frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>005</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>02238</th>\n",
       "      <th>02p</th>\n",
       "      <th>03</th>\n",
       "      <th>030</th>\n",
       "      <th>0358</th>\n",
       "      <th>...</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoology</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zq</th>\n",
       "      <th>zs</th>\n",
       "      <th>zuma</th>\n",
       "      <th>zv</th>\n",
       "      <th>zx</th>\n",
       "      <th>zz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  005  01  02  02238  02p  03  030  0358  ...  zone  zoo  zoology  \\\n",
       "0   0    0    0   0   0      0    0   0    0     0  ...     0    0        0   \n",
       "1   0    0    0   0   0      0    0   0    0     0  ...     0    0        0   \n",
       "2   0    0    0   0   0      0    0   0    0     0  ...     0    0        0   \n",
       "\n",
       "   zoom  zq  zs  zuma  zv  zx  zz  \n",
       "0     0   0   0     2   0   0   0  \n",
       "1     0   0   0     0   0   0   0  \n",
       "2     0   0   0     0   0   0   0  \n",
       "\n",
       "[3 rows x 10000 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>005</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>02238</th>\n",
       "      <th>02p</th>\n",
       "      <th>03</th>\n",
       "      <th>030</th>\n",
       "      <th>0358</th>\n",
       "      <th>...</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoology</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zq</th>\n",
       "      <th>zs</th>\n",
       "      <th>zuma</th>\n",
       "      <th>zv</th>\n",
       "      <th>zx</th>\n",
       "      <th>zz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  005   01   02  02238  02p   03  030  0358  ...  zone  zoo  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0   0.0  ...   0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0   0.0  ...   0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0   0.0  ...   0.0  0.0   \n",
       "\n",
       "   zoology  zoom   zq   zs      zuma   zv   zx   zz  \n",
       "0      0.0   0.0  0.0  0.0  0.007576  0.0  0.0  0.0  \n",
       "1      0.0   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  \n",
       "2      0.0   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  \n",
       "\n",
       "[3 rows x 10000 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_counts.toarray(), columns=count_vect.get_feature_names_out()).head(3)\n",
    "X_train_normalized = preprocessing.normalize(X_train_counts, norm='l1')\n",
    "pd.DataFrame(X_train_normalized.toarray(), columns=count_vect.get_feature_names_out()).head(3)\n",
    "#X_train_normalized.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Money time! Time to train the classifier. We will use the Naive Bayes classifier (SVM works well for texts as well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nb = MultinomialNB().fit(X_train_normalized, twenty_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's evaluate the model on the test set. But...\n",
    "\n",
    "Before we run it, we need to pass it through the same steps of feature extraction, filtering and normalization (exactly as in train phase). We have to use the same vectorizer object (otherwise we will get different feature ids). This can be complicated, and that's why we have the `pipeline` object that come to our help:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pipeline` Object\n",
    "\n",
    "In order to make the vectorizer => transformer => classifier easier to work with, scikit-learn provides a Pipeline class that behaves like a compound classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_clf_nb = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words=\"english\",max_features=10000)),\n",
    "    ('norm', preprocessing.Normalizer(norm='l1')),\n",
    "    ('clf_nb', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names vect, norm and clf (classifier) are arbitrary. We can use them for example to perform grid search for suitable hyperparameters. We will now train the model with a single command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(max_features=10000, stop_words='english')),\n",
       "                ('norm', Normalizer(norm='l1')), ('clf_nb', MultinomialNB())])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nb = text_clf_nb.fit(twenty_train.data, twenty_train.target)\n",
    "clf_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what's next? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "correct, evaluation on test set. Evaluating the predictive accuracy of the model is equally easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6481678173127987"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=12)\n",
    "docs_test = twenty_test.data\n",
    "predicted = text_clf_nb.predict(docs_test)\n",
    "np.mean(predicted == twenty_test.target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieved 64.8% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       1.00      0.03      0.06       319\n",
      "           comp.graphics       0.59      0.70      0.64       389\n",
      " comp.os.ms-windows.misc       0.65      0.78      0.71       394\n",
      "comp.sys.ibm.pc.hardware       0.60      0.71      0.65       392\n",
      "   comp.sys.mac.hardware       0.89      0.58      0.70       385\n",
      "          comp.windows.x       0.74      0.72      0.73       395\n",
      "            misc.forsale       0.68      0.85      0.76       390\n",
      "               rec.autos       0.64      0.84      0.73       396\n",
      "         rec.motorcycles       0.60      0.91      0.72       398\n",
      "      rec.sport.baseball       0.44      0.89      0.59       397\n",
      "        rec.sport.hockey       0.80      0.91      0.85       399\n",
      "               sci.crypt       0.73      0.85      0.79       396\n",
      "         sci.electronics       0.74      0.47      0.57       393\n",
      "                 sci.med       0.74      0.63      0.68       396\n",
      "               sci.space       0.80      0.84      0.82       394\n",
      "  soc.religion.christian       0.43      0.93      0.59       398\n",
      "      talk.politics.guns       0.84      0.21      0.34       364\n",
      "   talk.politics.mideast       1.00      0.56      0.72       376\n",
      "      talk.politics.misc       0.00      0.00      0.00       310\n",
      "      talk.religion.misc       0.00      0.00      0.00       251\n",
      "\n",
      "                accuracy                           0.65      7532\n",
      "               macro avg       0.65      0.62      0.58      7532\n",
      "            weighted avg       0.66      0.65      0.61      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "    target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Exercise 1\n",
    "We have defined a subset below of 4 categories from 20 newsgroup. Build a classifier to classify an unseen document into any of the 4 categories. This time use only top 1000 features, and no function words. Evaluate your performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "\n",
    "train_data = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=32)\n",
    "\n",
    "test_data = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(max_features=1000)),\n",
       "                ('norm', Normalizer(norm='l1')), ('clf_nb', MultinomialNB())])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.6418109187749668"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(max_features=1000, stop_words='english')),\n",
       "                ('norm', Normalizer(norm='l1')),\n",
       "                ('clf',\n",
       "                 SGDClassifier(alpha=0.001, max_iter=5, random_state=42,\n",
       "                               tol=None))])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7789613848202397"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# My sol\n",
    "text_clf_nb = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features=1000)),\n",
    "    ('norm', preprocessing.Normalizer(norm='l1')),\n",
    "    ('clf_nb', MultinomialNB()),\n",
    "])\n",
    "text_clf_nb.fit(train_data.data, train_data.target)\n",
    "predicted = text_clf_nb.predict(test_data.data)\n",
    "np.mean(predicted == test_data.target)\n",
    "\n",
    "\n",
    "# pipeline exercise 1 - solution\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words=\"english\",max_features=1000)),\n",
    "    ('norm', preprocessing.Normalizer(norm='l1')),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None)),\n",
    "])\n",
    "text_clf.fit(train_data.data, train_data.target)\n",
    "y_pred = text_clf.predict(test_data.data)\n",
    "np.mean(y_pred == test_data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you display a confusion matrix? Which categories were confused? What can you do to fix it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alt.atheism</th>\n",
       "      <th>comp.graphics</th>\n",
       "      <th>sci.med</th>\n",
       "      <th>soc.religion.christian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alt.atheism</th>\n",
       "      <td>156</td>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.graphics</th>\n",
       "      <td>3</td>\n",
       "      <td>375</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.med</th>\n",
       "      <td>9</td>\n",
       "      <td>101</td>\n",
       "      <td>261</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soc.religion.christian</th>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        alt.atheism  comp.graphics  sci.med  \\\n",
       "alt.atheism                     156             29       20   \n",
       "comp.graphics                     3            375        6   \n",
       "sci.med                           9            101      261   \n",
       "soc.religion.christian            9             11        0   \n",
       "\n",
       "                        soc.religion.christian  \n",
       "alt.atheism                                114  \n",
       "comp.graphics                                5  \n",
       "sci.med                                     25  \n",
       "soc.religion.christian                     378  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(metrics.confusion_matrix(y_pred=y_pred ,y_true=test_data.target), columns=train_data.target_names, index=train_data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(max_features=1000, stop_words='english')),\n",
       "                ('norm', Normalizer(norm='l1')), ('clf_nb', MultinomialNB())])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7336884154460719"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alt.atheism</th>\n",
       "      <th>comp.graphics</th>\n",
       "      <th>sci.med</th>\n",
       "      <th>soc.religion.christian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alt.atheism</th>\n",
       "      <td>41</td>\n",
       "      <td>31</td>\n",
       "      <td>67</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.graphics</th>\n",
       "      <td>0</td>\n",
       "      <td>370</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.med</th>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>314</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soc.religion.christian</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        alt.atheism  comp.graphics  sci.med  \\\n",
       "alt.atheism                      41             31       67   \n",
       "comp.graphics                     0            370       14   \n",
       "sci.med                           0             71      314   \n",
       "soc.religion.christian            0             18        3   \n",
       "\n",
       "                        soc.religion.christian  \n",
       "alt.atheism                                180  \n",
       "comp.graphics                                5  \n",
       "sci.med                                     11  \n",
       "soc.religion.christian                     377  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To fix confusion, add stop_words='english'\n",
    "text_clf_nb = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words='english', max_features=1000)),\n",
    "    ('norm', preprocessing.Normalizer(norm='l1')),\n",
    "    ('clf_nb', MultinomialNB()),\n",
    "])\n",
    "\n",
    "text_clf_nb.fit(train_data.data, train_data.target)\n",
    "predicted = text_clf_nb.predict(test_data.data)\n",
    "np.mean(predicted == test_data.target)\n",
    "\n",
    "pd.DataFrame(metrics.confusion_matrix(y_pred=predicted ,y_true=test_data.target), columns=train_data.target_names, index=train_data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "326.95px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
